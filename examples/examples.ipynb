{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meliora import jeffreys_test\n",
    "\n",
    "# Create a random dataset\n",
    "ratings = random.choices(['A', 'B', 'C'],  [0.4, 0.5, 0.1], k=1000)\n",
    "default_flag = random.choices([0, 1],  [0.9, 0.1], k=1000)\n",
    "probs_default = [np.clip(random.normalvariate(0.1, 0.05), 0, 1) for x in range(1000)]\n",
    "test_data = pd.DataFrame({'ratings': ratings, \n",
    "                                'default_flag': default_flag, \n",
    "                                'predicted_pd' : probs_default})\n",
    "\n",
    "# Test Jeffreys test\n",
    "from meliora import jeffreys_test\n",
    "jeffreys_test(test_data, 'ratings', 'default_flag', 'probs_default')\n",
    "\n",
    "# Test Jeffrey's test\n",
    "df = pd.read_csv('pd_test_data.csv')\n",
    "result= jeffreys_test(df, 'ratings', 'default_flag', 'predicted_pd', 0.05)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jeffrey's test\n",
    "jeffreys_test(test_data, \"ratings\", \"default_flag\", \"predicted_pd\", alpha_level=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binomial test\n",
    "binomial_test(test_data, \"ratings\", \"default_flag\", \"predicted_pd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brier score\n",
    "brier_score(test_data, \"ratings\", \"default_flag\", \"predicted_pd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Herfindahl test\n",
    "\n",
    "ratings2 = random.choices(buckets,  [0.4, 0.5, 0.1], k=1000)\n",
    "probs_default2 = [bucket_pds[rating] for rating in ratings2]\n",
    "default_flag2 = [random.uniform(0, 1) < bucket_pds[rating]\n",
    "                for rating in ratings2]\n",
    "test_data2 = pd.DataFrame({'ratings': ratings2, \n",
    "                         'default_flag': [int(i) for i in default_flag2], \n",
    "                         'predicted_pd' : probs_default2})\n",
    "\n",
    "test_data2.to_csv('pd_test_data2.csv', index=False)\n",
    "\n",
    "herfindahl_test(test_data, test_data2, \"ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hosmer-Lemeshow test\n",
    "hosmer_test(test_data, \"ratings\", \"default_flag\", \"predicted_pd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spiegelhalter test\n",
    "spiegelhalter_test(test_data, \"ratings\", \"default_flag\", \"predicted_pd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eabca979b0553fa6d87e9a00c352604d3b703d4afc9641643dd42376492b80f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
